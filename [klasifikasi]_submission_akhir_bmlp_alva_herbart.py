# -*- coding: utf-8 -*-
"""[Klasifikasi]_Submission_Akhir_BMLP_Alva_Herbart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17-wCm6mB8gg5k29OC_YsNgdSLKEp4Euj

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

df = pd.read_csv('clustered_nigeria_houses_data.csv')
df.head()

df.info()

df.describe()

plt.figure(figsize=(8, 4))
sns.countplot(x='cluster', data=df, palette='viridis')
plt.title('Distribusi Variabel Target')
plt.show()

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

data_features = df.drop('cluster', axis=1)
data_labels = df['cluster']
features_train, features_test, labels_train, labels_test = train_test_split(
    data_features, data_labels, test_size=0.2, random_state=42
)

print(f"Training set shape: features_train={features_train.shape}, labels_train={labels_train.shape}")
print(f"Test set shape: features_test={features_test.shape}, labels_test={labels_test.shape}")

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

# Membuat model
dt = DecisionTreeClassifier()
knn = KNeighborsClassifier()
svm = SVC()
lc = LogisticRegression()

# Melatih model
dt = dt.fit(features_train, labels_train)
knn.fit(features_train, labels_train)
svm.fit(features_train, labels_train)
lc.fit(features_train, labels_train)

print("Model training selesai.")

"""Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.
"""

def evaluate_model(model, features_test, labels_test):
    labels_pred = model.predict(features_test)

    results = {
        'Accuracy': accuracy_score(labels_test, labels_pred),
        'Precision': precision_score(labels_test, labels_pred, average='macro', zero_division=0),
        'Recall': recall_score(labels_test, labels_pred, average='macro'),
        'F1-Score': f1_score(labels_test, labels_pred, average='macro')
    }
    return results

# Mengevaluasi setiap model dan mengumpulkan hasilnya
results = {

    'Decision Tree (DT)': evaluate_model(dt, features_test, labels_test),
    'K-Nearest Neighbors (KNN)': evaluate_model(knn, features_test, labels_test),
    'Support Vector Machine (SVM)': evaluate_model(svm, features_test, labels_test),
    'Logistic Regression (LC)': evaluate_model(lc, features_test, labels_test)
}

# Buat DataFrame untuk meringkas hasil
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Isi DataFrame dengan hasil
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Konversi daftar kamus ke DataFrame
summary_df = pd.DataFrame(rows)

# Tampilkan DataFrame
print(summary_df)

def plot_confusion_matrix(model, features_test, labels_test, model_name):
    labels_pred = model.predict(features_test)
    cm = confusion_matrix(labels_test, labels_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

# Plot confusion matrix for each model
plot_confusion_matrix(dt, features_test, labels_test, 'Decision Tree (DT)')
plot_confusion_matrix(knn, features_test, labels_test, 'K-Nearest Neighbors (KNN)')
plot_confusion_matrix(svm, features_test, labels_test, 'Support Vector Machine (SVM)')
plot_confusion_matrix(lc, features_test, labels_test, 'Logistic Regression (LC)')

"""Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.

## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

# Hyperparameter tuning for each model (Optional)
print("Tuning hyperparameters...")

# RancomizedSearchCV for Decision Tree
dt_params = {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 10, 20], 'min_samples_leaf': [1, 5, 10]}
dt_random = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=3, scoring='f1_macro')
dt_random.fit(features_train, labels_train)

# RancomizedSearchCV for KNN
knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
knn_random = RandomizedSearchCV(KNeighborsClassifier(), knn_params, cv=3, scoring='f1_macro')
knn_random.fit(features_train, labels_train)

# RancomizedSearchCV for SVM
svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_random = RandomizedSearchCV(SVC(random_state=42), svm_params, n_iter=5, cv=3, scoring='f1_macro', random_state=42)
svm_random.fit(features_train_scaled, labels_train)

# RandomizedSearchCV for Logistic Regression
lc_params = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'max_iter': [100, 200, 300]
}
lc_random = RandomizedSearchCV(LogisticRegression(random_state=42), lc_params, cv=3, scoring='f1_macro', n_iter=10, random_state=42)
lc_random.fit(features_train_scaled, labels_train)

scaler = StandardScaler()
features_train_scaled = scaler.fit_transform(features_train)
features_test_scaled = scaler.transform(features_test)

# Hyperparameter tuning for each model (Optional)
print("Tuning hyperparameters...")

# RancomizedSearchCV for Decision Tree
dt_params = {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 10, 20], 'min_samples_leaf': [1, 5, 10]}
dt_random = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=3, scoring='f1_macro')
dt_random.fit(features_train, labels_train)

# RancomizedSearchCV for KNN
knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
knn_random = RandomizedSearchCV(KNeighborsClassifier(), knn_params, cv=3, scoring='f1_macro')
knn_random.fit(features_train, labels_train)

# RancomizedSearchCV for SVM
svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_random = RandomizedSearchCV(SVC(random_state=42), svm_params, n_iter=5, cv=3, scoring='f1_macro', random_state=42)
svm_random.fit(features_train_scaled, labels_train)

# RandomizedSearchCV for Logistic Regression
lc_params = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'max_iter': [100, 200, 300]
}
lc_random = RandomizedSearchCV(LogisticRegression(random_state=42), lc_params, cv=3, scoring='f1_macro', n_iter=10, random_state=42)
lc_random.fit(features_train_scaled, labels_train)

# Best hyperparameters
print("Best hyperparameters for Decision Tree:", dt_random.best_params_)
print("Best hyperparameters for KNN:", knn_random.best_params_)
print("Best hyperparameters for SVM:", svm_random.best_params_)
print("Best hyperparameters for Logistic Regression:", lc_random.best_params_)

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

# Evaluasi model dengan hyperparameter terbaik
best_dt_model = dt_random.best_estimator_
best_knn_model = knn_random.best_estimator_
best_svm_model = svm_random.best_estimator_
best_lc_model = lc_random.best_estimator_

tuned_results = {
    'Decision Tree (Tuned)': evaluate_model(best_dt_model, features_test, labels_test),
    'K-Nearest Neighbors (Tuned)': evaluate_model(best_knn_model, features_test, labels_test),
    'Support Vector Machine (Tuned)': evaluate_model(best_svm_model, features_test_scaled, labels_test),
    'Logistic Regression (Tuned)': evaluate_model(best_lc_model, features_test_scaled, labels_test)
}

tuned_summary_df = pd.DataFrame(tuned_results).T
print("Results after tuning:")
print(tuned_summary_df)

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).

Hasil evaluasi sebelum di tuning

Model | Accuracy | Precision | Recall | F1-Score

*   Decision Tree (DT) | 0.999532 | 0.998737 | 0.999511	| 0.999123
*   K-Nearest Neighbors (KNN) |	0.999532 |	0.998737 |	0.999511 | 0.999123
*   Support Vector Machine (SVM) | 0.999532	| 0.998737 | 0.999511 | 0.999123
*   Logistic Regression (LC) | 0.748831 | 0.698444 | 0.730644 | 0.711889


Hasil evaluasi setelah di tuning

Model | Accuracy | Precision | Recall | F1-Score
*   Decision Tree (Tuned) | 0.999532 | 0.998737 | 0.999511	| 0.999123
*   K-Nearest Neighbors (Tuned) |	0.999532 |	0.998737 |	0.999511 | 0.999123
*   Support Vector Machine (Tuned) | 1.000000	| 1.000000 | 1.000000 | 1.000000
*   Logistic Regression (Tuned) | 0.999532 | 0.998737 | 0.999511 | 0.999123

**Decision Tree dan KNN:**

Sebelum Tuning: Kedua model menunjukkan metrik evaluasi yang sangat tinggi, hampir mencapai skor sempurna.

Setelah Tuning: Tidak ada peningkatan yang signifikan setelah tuning, yang menunjukkan bahwa model Decision Tree dan KNN sudah cukup optimal sebelum tuning.

**Support Vector Machine (SVM):**

Sebelum Tuning: Model SVM menunjukkan metrik evaluasi yang sangat tinggi, hampir mencapai skor sempurna.

Setelah Tuning: Model SVM mencapai skor sempurna untuk semua metrik evaluasi, yang menunjukkan bahwa tuning hyperparameter berhasil meningkatkan performa model.

**Logistic Regression (LC):**

Sebelum Tuning: Model Logistic Regression menunjukkan metrik evaluasi yang cukup baik, dengan akurasi sekitar 74.88%.

Setelah Tuning: Model Logistic Regression menunjukkan peningkatan performa yang signifikan, mencapai metrik evaluasi yang hampir sempurna, yang menunjukkan bahwa tuning hyperparameter sangat efektif.

2. Identifikasi kelemahan model, seperti:
  - Precision atau Recall rendah untuk kelas tertentu.
  Semua model menunjukkan metrik evaluasi yang sangat tinggi setelah tuning, sehingga tidak ada kelas tertentu yang memiliki precision atau recall yang rendah.

  - Apakah model mengalami overfitting atau underfitting?
   Model SVM dan Logistic Regression setelah tuning menunjukkan metrik evaluasi yang sangat tinggi, yang dapat mengindikasikan kemungkinan overfitting.

3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.
Gunakan cross-validation yang lebih ekstensif untuk memastikan bahwa hasil evaluasi konsisten dan model tidak mengalami overfitting. Lakukan tuning hyperparameter yang lebih ekstensif menggunakan GridSearchCV untuk mencoba lebih banyak kombinasi hyperparameter. Eksplorasi algoritma lain seperti Random Forest atau Gradient Boosting untuk melihat apakah ada peningkatan performa lebih lanjut. Jika memungkinkan, tambahkan lebih banyak data untuk meningkatkan generalisasi model.
"""